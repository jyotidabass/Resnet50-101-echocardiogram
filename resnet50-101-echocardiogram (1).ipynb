{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport torch\nfrom torchvision import datasets, models, transforms\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torch.autograd import Variable\nimport time\ninput_path = \"../input/data-chamber/DATA_CHAMBER_2021/\" \nuse_gpu = torch.cuda.is_available()\nif use_gpu:\n    print(\"Using CUDA\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-17T07:12:26.072301Z","iopub.execute_input":"2022-08-17T07:12:26.072603Z","iopub.status.idle":"2022-08-17T07:12:27.984494Z","shell.execute_reply.started":"2022-08-17T07:12:26.072514Z","shell.execute_reply":"2022-08-17T07:12:27.983458Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class ImageFolderWithPaths(datasets.ImageFolder):\n    \"\"\"Custom dataset that includes image file paths. Extends\n    torchvision.datasets.ImageFolder\n    \"\"\"\n\n    # override the __getitem__ method. this is the method that dataloader calls\n    def __getitem__(self, index):\n        # this is what ImageFolder normally returns \n        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n        # the image file path\n        path = self.imgs[index][0]\n        # make a new tuple that includes original and the path\n        tuple_with_path = (original_tuple + (path,))\n        return tuple_with_path","metadata":{"execution":{"iopub.status.busy":"2022-08-17T07:12:27.986327Z","iopub.execute_input":"2022-08-17T07:12:27.986878Z","iopub.status.idle":"2022-08-17T07:12:27.993152Z","shell.execute_reply.started":"2022-08-17T07:12:27.986837Z","shell.execute_reply":"2022-08-17T07:12:27.992290Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n\ndata_transforms = {\n    'train':\n    transforms.Compose([\n        transforms.Resize(224),\n        transforms.CenterCrop(224),\n#         transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n#         transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        normalize\n    ]),\n    'validation':\n    transforms.Compose([\n        transforms.Resize(224),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        normalize\n    ]),\n}\n\nimage_datasets = {\n    'train': \n    ImageFolderWithPaths(input_path + 'train', data_transforms['train']),\n    'validation': \n    ImageFolderWithPaths(input_path + 'test', data_transforms['validation'])\n}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train','validation']}\n\ndataloaders = {\n    'train':\n    torch.utils.data.DataLoader(image_datasets['train'],\n                                batch_size=8,\n                                shuffle=True,\n                                num_workers=2),  # for Kaggle\n    'validation':\n    torch.utils.data.DataLoader(image_datasets['validation'],\n                                batch_size=8,\n                                shuffle=True,\n                                num_workers=2)  # for Kaggle\n}","metadata":{"execution":{"iopub.status.busy":"2022-08-17T07:12:27.994650Z","iopub.execute_input":"2022-08-17T07:12:27.994903Z","iopub.status.idle":"2022-08-17T07:12:31.489961Z","shell.execute_reply.started":"2022-08-17T07:12:27.994869Z","shell.execute_reply":"2022-08-17T07:12:31.489190Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-08-17T07:12:31.492173Z","iopub.execute_input":"2022-08-17T07:12:31.492424Z","iopub.status.idle":"2022-08-17T07:12:31.501349Z","shell.execute_reply.started":"2022-08-17T07:12:31.492391Z","shell.execute_reply":"2022-08-17T07:12:31.499321Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#!pip install efficientnet_pytorch ","metadata":{"execution":{"iopub.status.busy":"2022-08-17T07:12:31.502667Z","iopub.execute_input":"2022-08-17T07:12:31.503471Z","iopub.status.idle":"2022-08-17T07:12:31.509181Z","shell.execute_reply.started":"2022-08-17T07:12:31.503436Z","shell.execute_reply":"2022-08-17T07:12:31.508422Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#from efficientnet_pytorch import EfficientNet","metadata":{"execution":{"iopub.status.busy":"2022-08-17T07:12:31.510652Z","iopub.execute_input":"2022-08-17T07:12:31.510979Z","iopub.status.idle":"2022-08-17T07:12:31.517948Z","shell.execute_reply.started":"2022-08-17T07:12:31.510945Z","shell.execute_reply":"2022-08-17T07:12:31.517316Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#model = EfficientNet.from_pretrained('efficientnet-b0').cuda()\nmodel = models.resnet50(pretrained = True).cuda()\nfor param in model.parameters():\n    param.requires_grad = False   \n    \nmodel.fc = nn.Sequential(\n               nn.Linear(2048, 128),\n               nn.ReLU(inplace=True),\n               nn.Linear(128, 3)).to(device)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T07:12:31.519258Z","iopub.execute_input":"2022-08-17T07:12:31.519444Z","iopub.status.idle":"2022-08-17T07:12:41.313569Z","shell.execute_reply.started":"2022-08-17T07:12:31.519421Z","shell.execute_reply":"2022-08-17T07:12:41.312793Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.fc.parameters(),lr=0.001,momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T07:12:41.314897Z","iopub.execute_input":"2022-08-17T07:12:41.315332Z","iopub.status.idle":"2022-08-17T07:12:41.320711Z","shell.execute_reply.started":"2022-08-17T07:12:41.315295Z","shell.execute_reply":"2022-08-17T07:12:41.320044Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, num_epochs=3):\n    train_batches = len(dataloaders['train'])\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n        print('-' * 10)\n\n        for phase in ['train']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for i,data in enumerate(dataloaders[phase]):\n                inputs, labels,_ = data\n                print(\"\\rTraining batch {}/{}\".format(i+1, train_batches), end='', flush=True)\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n\n                if phase == 'train':\n                    optimizer.zero_grad()\n                    loss.backward()\n                    optimizer.step()\n\n                _, preds = torch.max(outputs, 1)\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / len(image_datasets[phase])\n            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n\n            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n                                                        epoch_loss,\n                                                        epoch_acc))\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-08-17T07:12:41.321938Z","iopub.execute_input":"2022-08-17T07:12:41.322344Z","iopub.status.idle":"2022-08-17T07:12:41.333341Z","shell.execute_reply.started":"2022-08-17T07:12:41.322306Z","shell.execute_reply":"2022-08-17T07:12:41.332606Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model_trained = train_model(model, criterion, optimizer, num_epochs=20)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T07:12:41.336070Z","iopub.execute_input":"2022-08-17T07:12:41.336426Z","iopub.status.idle":"2022-08-17T07:31:06.470602Z","shell.execute_reply.started":"2022-08-17T07:12:41.336385Z","shell.execute_reply":"2022-08-17T07:31:06.469406Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\ndef test_model(model, criterion, optimizer):\n    labels_input=list()\n    labels_output=list()\n    vid_id = list()\n    for phase in ['validation']:\n        model.eval()\n\n        running_loss = 0.0\n        running_corrects = 0\n\n        for inputs, labels, fname in dataloaders[phase]:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            labels_input= labels_input + labels.tolist()\n            for f in fname:\n                vid_id.append(f.split('/')[-1].split('.')[0].split('_')[0])\n            outputs = model(inputs)\n            \n            loss = criterion(outputs, labels)\n            _, preds = torch.max(outputs, 1)\n            \n            labels_output= labels_output + preds.tolist()\n    return labels_input,labels_output,vid_id\n            \ny_true,y_pred,vid_id = test_model(model, criterion, optimizer)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T07:31:06.472797Z","iopub.execute_input":"2022-08-17T07:31:06.473115Z","iopub.status.idle":"2022-08-17T07:31:20.796367Z","shell.execute_reply.started":"2022-08-17T07:31:06.473073Z","shell.execute_reply":"2022-08-17T07:31:20.795317Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nprint(classification_report(y_true,y_pred))\naccuracy_score(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T07:31:20.798246Z","iopub.execute_input":"2022-08-17T07:31:20.798572Z","iopub.status.idle":"2022-08-17T07:31:21.542069Z","shell.execute_reply.started":"2022-08-17T07:31:20.798517Z","shell.execute_reply":"2022-08-17T07:31:21.541290Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.DataFrame(list(zip(y_true,y_pred,vid_id)),\n               columns =['y_true','y_pred','vid_id'])\ndf.to_csv('df.csv',encoding='utf-8',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T07:31:21.543498Z","iopub.execute_input":"2022-08-17T07:31:21.544015Z","iopub.status.idle":"2022-08-17T07:31:21.559280Z","shell.execute_reply.started":"2022-08-17T07:31:21.543976Z","shell.execute_reply":"2022-08-17T07:31:21.558423Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"vid_list = list(set(df['vid_id'].values))\n\ny_true = []\ny_pred = []\nfor vid in vid_list:\n    #print(vid)\n    tmp_df = df[df['vid_id']==vid]\n    #print(len(tmp_df))\n    vid_pred = tmp_df['y_pred'].mode().values[0]\n    vid_label = tmp_df['y_true'].mode().values[0]\n    y_true.append(vid_label)\n    y_pred.append(vid_pred)\n    #print(vid_label,\"\\n\",vid_pred)\n    \n    print('vid: {} label: {} pred: {}'.format(vid,vid_label,vid_pred))","metadata":{"execution":{"iopub.status.busy":"2022-08-17T07:31:21.560765Z","iopub.execute_input":"2022-08-17T07:31:21.561247Z","iopub.status.idle":"2022-08-17T07:31:21.626427Z","shell.execute_reply.started":"2022-08-17T07:31:21.561209Z","shell.execute_reply":"2022-08-17T07:31:21.625691Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_true,y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T07:31:21.627466Z","iopub.execute_input":"2022-08-17T07:31:21.627802Z","iopub.status.idle":"2022-08-17T07:31:21.635407Z","shell.execute_reply.started":"2022-08-17T07:31:21.627767Z","shell.execute_reply":"2022-08-17T07:31:21.634611Z"},"trusted":true},"execution_count":15,"outputs":[]}]}